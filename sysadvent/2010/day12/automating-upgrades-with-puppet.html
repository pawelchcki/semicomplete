<h1>Scale by Separating Inputs and Models</h1>

<p>This primarily is primarily about separating your configuration model from
your configuration inputs. You might have the same service model in multiple
environments but versions, accounts, ownership, etc, may change between them.
The 'scale' portion is that having independent inputs and models is related
to scaling operability and sanity.</p>

<p>Puppet and other configuration tools help you describe your infrastructure.
Puppet's model is resources: files, users, packages, etc. Each resource has
attributes like package version, file path, file contents, service restart
command, package provider (gem, apt, yum), user uid, etc.</p>

<p>Many of my puppet manifests look a bit like this:</p>

<pre><code>class nginx::server {
  package {
    "nginx": ensure =&gt; "0.8.52";
  }
  ...
}
</code></pre>

<p>To upgrade versions, I would just edit the manifest and change the version.</p>

<p>Static manifests don't scale very well. Puppet has support for environments so
you can use different manifests (say, a different nginx::server class) in
different situations. You could do tihs:</p>

<pre><code>class nginx::server {
  package {
    "nginx":
      ensure =&gt; $environment {
        "production" =&gt; "0.8.52",
        "testing" =&gt; "0.8.53",
        "dev" =&gt; "latest",
      };
  }
}
</code></pre>

<p>The variable above comes from puppet calls a 'fact.' Facts such as cpu speed,
ip addresses, chassis info, virtualization source, etc, are provided to help
you conditionally tune your infrastructure. Facts come from a puppet tool
called Facter, which means facts are essentially an external input for puppet.</p>

<p>This model of external inputs is a good one. Using facts, you could conditionally
install things like Dell OpenManage, or template service configs based on ram
or cpu counts. Combining the inputs (facts) with your model (puppet resources)
helps you steer puppet into doing the correct thing for each machine it is run on.
Very useful!</p>

<p>The problem with the above puppet example is that it doesn't scale very well.
Each time you add a new environment (a new testing environment, some one-off
dev cluster, etc), you have to edit the manifest (your infrastructure model).</p>

<p>The solution here is to follow the facts example and allow yourself a way to
specify your own inputs - what I would call, "truth," Truth is very similar to
facts, just more human-driven and I only use a different, but similar, term for
the sake of identifying source. I use "truth" to refer to human-originated
inputs (such as "what package to install"), and I use "facts" to refer to
machine-originated information (such as "number of cpus on this system").</p>

<p>For the above puppet manifest, you could write truth in separate manifest that
defines <code>$nginx_version</code> based on <code>$environment</code>:</p>

<pre><code># truth.pp
case $environment {
  "production": { $nginx_version = "0.8.52" }
  "testing": { $nginx_version = "0.8.53" }
  "dev": { $nginx_version =  "latest" }
}

# modules/nginx/manifests/server.pp
class nginx::server {
  package {
    "nginx": ensure =&gt; $nginx_version;
  }
}
</code></pre>

<p>Ultimately, setting variables with conditionals (case statements, etc) is more
code than you need - in Puppet 2.6.1, a solution to this problem was included:
<a href="http://docs.puppetlabs.com/references/stable/function.html#extlookup">extlookup</a>().
(It existed prior, but it now officially ships with puppet)</p>

<p>This new function lets you separate your configuration inputs from your
infrastructure model. An example of the above manifest using extlookup:</p>

<pre><code>class nginx::server {
  package {
    "nginx": ensure =&gt; extlookup("package/nginx");
  }
}
</code></pre>

<p>You configure extlookup in puppet by setting some variables, here's an example:</p>

<pre><code>$extlookup_datadir = "/etc/puppet/manifests/extdata"
$extlookup_precedence = ["nodes/%{fqdn}", "environments/%{environment}", "common"]
</code></pre>

<p>The values in <code>%{ ... }</code> are evaluated with each node's facts. This lets you
put all production environment data in
<code>/etc/puppet/manifests/extdata/environments/**production**.csv</code>.</p>

<p>With the above configuration, I can easily add per-node and per-environment
package versions for nginx. If all else fails, I can provide a default package
version in the 'common' setting above. You can also easily extend the configuration
to include more sources without modifying your infrastructure model.</p>

<p>You data format extlookup uses currently is
<a href="http://en.wikipedia.org/wiki/Comma-separated_values">csv</a> files.  It's
basically a bunch of key-value pairs you can query with a precedence order. For
example, the above config would look in <code>nodes/somehostname.csv</code> first, which
would allow you to override environment-specific configuration values per host,
but if no <code>nodes/somehostname.csv</code> file exists or the requested value is not
present, it will fall down to the next file in the list. You can also specify
default values in extlookup, but that is outside the scope of this article.</p>

<p>Building on the examples above, here is what your extlookup files would look like:</p>

<pre><code># /etc/puppet/manifests/extdata/environments/production.csv
package/nginx,0.8.52

# /etc/puppet/manifests/extdata/environments/testing.csv
package/nginx,0.8.53

# /etc/puppet/manifests/extdata/environments/dev.csv
package/nginx,latest
</code></pre>

<p>I use extlookup for:</p>

<ul>
<li>package versions. Of note, for developer systems, I set some package
values to "absent" so developer activity won't be overwritten by puppet
trying to deploy our internal apps.</li>
<li>application flags and tuning. For production, we want to do backups to Amazon S3. For random development systems, we don't.</li>
<li>syslog configuration (what remote syslog host to ship logs to, per deployment)</li>
<li>database information (database name, credentials, etc)</li>
<li>some dns automation (what certain internal CNAME records point to)</li>
<li>nagios contact configuration (example: notify pager in prod 24/7, only during daytime for staging, but never for development)</li>
</ul>

<p>Point is, once you separate your model from your inputs (facts, truth, etc),
you become more agile: </p>

<ul>
<li>You can then tune settings per machine, per environment, or per any other value,</li>
<li>All of your truth inputs are concentrated in one place. This has an
additional benefit of allowing non-puppet users (in this example)  to upgrade or tune
values without needing puppet knowledge.</li>
<li>If you author puppet modules, you can release modules with extlookup support
and document the values used. This allows users of your module to be happily ignorant
of the internals of your module.</li>
</ul>

<p>In closing, separating your model from your inputs increases testability and
maintainability of your infrsatructure automation. Further, adding a human
input source (truth) in addition to machine inputs (facts) can help you tune
your infrastructure for any situation.</p>

<p>Further reading:</p>

<ul>
<li><a href="http://www.puppetlabs.com/puppet-3/related-projects/facter/">Puppet facts with Facter</a></li>
<li><a href="http://wiki.opscode.com/display/chef/Ohai">Chef facts with Ohai</a></li>
<li><a href="http://www.devco.net/archives/2009/08/31/complex_data_and_puppet.php">Complex data and Puppet</a></li>
</ul>
